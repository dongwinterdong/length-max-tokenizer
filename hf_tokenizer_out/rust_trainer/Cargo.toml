[package]
name = "length_tokenizer"
version = "0.1.0"
edition = "2021"

[dependencies]
anyhow = "1"
clap = { version = "4", features = ["derive"] }
hashbrown = { version = "0.14", features = ["serde", "rayon"] }
 rayon = "1.8"
 serde = { version = "1", features = ["derive"] }
 serde_json = "1"
 ahash = "0.8"
 num_cpus = "1.16"
 bincode = "1.3"
 crossbeam-channel = "0.5"
smallvec = { version = "1.13", features = ["serde"] }
humantime = "2.1"

# Parquet 语料读取（FineWeb / FineWeb-Edu）
arrow = "54"
parquet = { version = "54", features = ["arrow"] }

[target.'cfg(not(target_env = "msvc"))'.dependencies]
tikv-jemallocator = "0.5"

[profile.release]
opt-level = 3
lto = true
codegen-units = 1

